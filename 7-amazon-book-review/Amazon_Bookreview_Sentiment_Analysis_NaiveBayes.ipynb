{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Store the usefull information from this huge dataset\n",
    "dataset = {}\n",
    "dataset[\"review_text\"] = []\n",
    "dataset['rating'] = []\n",
    "count = 0\n",
    "with open ('Books_5.json') as Train_json:\n",
    "    for i in Train_json:\n",
    "        count+=1\n",
    "        if count % 20 == 0:\n",
    "            item = json.loads(i)\n",
    "            dataset[\"review_text\"].append(item[\"reviewText\"])\n",
    "            dataset[\"rating\"].append(item[\"overall\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444902\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>This book is everything that is simple, delica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>When I first started writing poetry at age 12 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Khalil Gibran's book, The Prophet, has the pow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I was given this book by a writer friend who c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A book to be treasured. A tremendous poet deal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                        review_text\n",
       "0     5.0  This book is everything that is simple, delica...\n",
       "1     5.0  When I first started writing poetry at age 12 ...\n",
       "2     5.0  Khalil Gibran's book, The Prophet, has the pow...\n",
       "3     5.0  I was given this book by a writer friend who c...\n",
       "4     5.0  A book to be treasured. A tremendous poet deal..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert Dataset to dataframe\n",
    "dataset_df = pd.DataFrame(dataset)\n",
    "print(len(dataset_df))\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_df_5 = dataset_df[dataset_df[\"rating\"]==5.0]\n",
    "dataset_df_4 = dataset_df[dataset_df[\"rating\"]==4.0]\n",
    "dataset_df_3 = dataset_df[dataset_df[\"rating\"]==3.0]\n",
    "dataset_df_2 = dataset_df[dataset_df[\"rating\"]==2.0]\n",
    "dataset_df_1 = dataset_df[dataset_df[\"rating\"]==1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset_df_1_train = dataset_df_1.iloc[0:5000,]\n",
    "dataset_df_1_test = dataset_df_1.iloc[5000:6000,]\n",
    "dataset_df_2_train = dataset_df_2.iloc[0:5000,]\n",
    "dataset_df_2_test = dataset_df_2.iloc[5000:6000,]\n",
    "dataset_df_3_train = dataset_df_3.iloc[0:5000,]\n",
    "dataset_df_3_test = dataset_df_3.iloc[5000:6000,]\n",
    "dataset_df_4_train = dataset_df_4.iloc[0:5000,]\n",
    "dataset_df_4_test = dataset_df_4.iloc[5000:6000,]\n",
    "dataset_df_5_train = dataset_df_5.iloc[0:5000,]\n",
    "dataset_df_5_test = dataset_df_5.iloc[5000:6000,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames_train = [dataset_df_5_train, dataset_df_4_train, dataset_df_3_train,dataset_df_2_train,dataset_df_1_train]\n",
    "frames_test = [dataset_df_5_test, dataset_df_4_test, dataset_df_3_test,dataset_df_2_test,dataset_df_1_test]\n",
    "\n",
    "dataset_df_train = pd.concat(frames_train)\n",
    "dataset_df_test = pd.concat(frames_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Clean the reviews\n",
    "def data_cleaning (raw_review_str):\n",
    "    ## remove potential HTML tag\n",
    "    review_text = BeautifulSoup(raw_review_str).get_text()\n",
    "    ## remove non-letter \n",
    "    review_letter = re.sub(\"[^a-zA-Z]\",\" \",review_text)\n",
    "    ## convert to lower case and split the list\n",
    "    review_lower_list = review_letter.lower().split()\n",
    "    ## remove stop words and stemming\n",
    "    stops_eng = set(stopwords.words(\"english\"))\n",
    "    stemmer = nltk.wordnet.WordNetLemmatizer()\n",
    "    review_nostopwords_stemmed = [stemmer.lemmatize(w) for w in review_lower_list]\n",
    "    review_nostopwords_stemmed = [stemmer.lemmatize(w) for w in review_lower_list if w not in stops_eng]\n",
    "    ## return \n",
    "    return \" \".join(review_nostopwords_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinmu/anaconda/envs/py36/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/xinmu/anaconda/envs/py36/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html.parser\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "dataset_df_train[\"review_cleaned\"] = dataset_df_train[\"review_text\"].apply(data_cleaning)\n",
    "dataset_df_test[\"review_cleaned\"] = dataset_df_test[\"review_text\"].apply(data_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Put all the review of train_set in a list to generate the features\n",
    "clean_train_reviews = []\n",
    "for i in dataset_df_train[\"review_cleaned\"]:\n",
    "    clean_train_reviews.append(i)\n",
    "\n",
    "clean_test_reviews = []\n",
    "for i in dataset_df_test[\"review_cleaned\"]:\n",
    "    clean_test_reviews.append(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Generate Features (bag of words)\n",
    "vectorizer = TfidfVectorizer(analyzer = \"word\", ngram_range=(1, 2), tokenizer = None, preprocessor = None, stop_words = None,max_features=20000)\n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "test_data_features = vectorizer.transform(clean_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "#print (vocab)\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 20000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 20000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_features = train_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data_features = test_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "y_pred_gnb = gnb.fit(train_data_features, dataset_df_train[\"rating\"]).predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 5000 points : 3278\n",
      "prediction accuracy is 0.344400\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (len(dataset_df_test),(dataset_df_test['rating'] != y_pred_gnb).sum()))\n",
    "print(\"prediction accuracy is %f\" % ((dataset_df_test['rating'] == y_pred_gnb).sum()/len(dataset_df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnb=MultinomialNB()\n",
    "y_pred_mnb = mnb.fit(train_data_features, dataset_df_train[\"rating\"]).predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 5000 points : 2633\n",
      "prediction accuracy is 0.473400\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (len(dataset_df_test),(dataset_df_test['rating'] != y_pred_mnb).sum()))\n",
    "print(\"prediction accuracy is %f\" % ((dataset_df_test['rating'] == y_pred_mnb).sum()/len(dataset_df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bnb = BernoulliNB()\n",
    "y_pred_bnb = bnb.fit(train_data_features, dataset_df_train[\"rating\"]).predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 5000 points : 2948\n",
      "prediction accuracy is 0.410400\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (len(dataset_df_test),(dataset_df_test['rating'] != y_pred_bnb).sum()))\n",
    "print(\"prediction accuracy is %f\" % ((dataset_df_test['rating'] == y_pred_bnb).sum()/len(dataset_df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
