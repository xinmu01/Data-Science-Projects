{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP/1.1 200 OK\r\n",
      "Content-Type: text/plain\r\n",
      "Content-Length: 167\r\n",
      "Connection: close\r\n",
      "Date: Fri, 11 Nov 2016 04:32:52 GMT\r\n",
      "Server: Apache\r\n",
      "Last-Modified: Fri, 04 Dec 2015 19:05:04 GMT\r\n",
      "ETag: \"a7-526172f5b5d89\"\r\n",
      "Accept-Ranges: bytes\r\n",
      "Cache-Control: max-age=604800, public\r\n",
      "Access-Control-Allow-Origin: *\r\n",
      "Access-Control-Allow-Headers: origin, x-requested-with, content-type\r\n",
      "Access-Control-Allow-Methods: GET\r\n",
      "\r\n",
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and\n",
      " kill the envious moon\n",
      "Who is already sick and pale with grief\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## This is a low-level to get file or image of the web server\n",
    "import socket\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('www.py4inf.com', 80))\n",
    "mysock.send('GET http://www.py4inf.com/code/romeo.txt HTTP/1.0\\n\\n')\n",
    "while True:\n",
    "    data = mysock.recv(512)\n",
    "    if ( len(data) < 1 ) :\n",
    "        break\n",
    "    print data\n",
    "mysock.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using urllib \n",
    "Using urllib, I can treat a web page much like a file. You simply indicate which web page you would like to retrieve and urllib handles all of the HTTP protocol and header details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "But soft what light through yonder window breaks\n",
      "It is the east and Juliet is the sun\n",
      "Arise fair sun and kill the envious moon\n",
      "Who is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "fhand = urllib.urlopen('http://www.py4inf.com/code/romeo.txt')\n",
    "for line in fhand:\n",
    "    print line.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing HTML using regular expressions\n",
    "One of the common uses of the urllib capability in Python is to scrape the web.\n",
    "Web scraping is when we write a program that pretends to be a web browser and\n",
    "retrieves pages, then examines the data in those pages looking for patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter - http://www.py4inf.com/book.htm\n",
      "http://amzn.to/1KkULF3\n",
      "http://amzn.to/1KkULF3\n",
      "http://amzn.to/1hLcoBy\n",
      "http://amzn.to/1KkV42z\n",
      "http://amzn.to/1fNOnbd\n",
      "http://amzn.to/1N74xLt\n",
      "http://do1.dr-chuck.net/py4inf/EN-us/book.pdf\n",
      "http://do1.dr-chuck.net/py4inf/ES-es/book.pdf\n",
      "http://www.xwmooc.net/python/\n",
      "http://fanwscu.gitbooks.io/py4inf-zh-cn/\n",
      "http://itunes.apple.com/us/book/python-for-informatics/id554638579?mt=13\n",
      "http://www-personal.umich.edu/~csev/books/py4inf/ibooks//python_for_informatics.ibooks\n",
      "http://www.py4inf.com/code\n",
      "http://www.greenteapress.com/thinkpython/thinkCSpy/\n",
      "http://allendowney.com/\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "url = raw_input('Enter - ')\n",
    "html = urllib.urlopen(url).read()\n",
    "#print html\n",
    "links = re.findall('href=\"(http://.*?)\"', html)\n",
    "for link in links:\n",
    "    print link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Beatifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named BeautifulSoup",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3a013113a9a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mBeautifulSoup\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named BeautifulSoup"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "from BeautifulSoup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [ipykernel_py2]",
   "language": "python",
   "name": "Python [ipykernel_py2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
