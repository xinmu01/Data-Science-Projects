{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = os.getcwd()\n",
    "filename = 'Books_5.json'\n",
    "datafile = os.path.join(directory, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/xinmu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Store the usefull information from this huge dataset\n",
    "dataset = {}\n",
    "dataset[\"review_text\"] = []\n",
    "dataset['rating'] = []\n",
    "count = 0\n",
    "with open (datafile) as Train_json:\n",
    "    for i in Train_json:\n",
    "        count+=1\n",
    "        if count % 20 == 0:\n",
    "            item = json.loads(i)\n",
    "            dataset[\"review_text\"].append(item[\"reviewText\"])\n",
    "            dataset[\"rating\"].append(item[\"overall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444902\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>This book is everything that is simple, delica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>When I first started writing poetry at age 12 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Khalil Gibran's book, The Prophet, has the pow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I was given this book by a writer friend who c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A book to be treasured. A tremendous poet deal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                        review_text\n",
       "0     5.0  This book is everything that is simple, delica...\n",
       "1     5.0  When I first started writing poetry at age 12 ...\n",
       "2     5.0  Khalil Gibran's book, The Prophet, has the pow...\n",
       "3     5.0  I was given this book by a writer friend who c...\n",
       "4     5.0  A book to be treasured. A tremendous poet deal..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Convert Dataset to dataframe\n",
    "dataset_df = pd.DataFrame(dataset)\n",
    "print(len(dataset_df))\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_df_5 = dataset_df[dataset_df[\"rating\"]==5.0]\n",
    "dataset_df_4 = dataset_df[dataset_df[\"rating\"]==4.0]\n",
    "dataset_df_3 = dataset_df[dataset_df[\"rating\"]==3.0]\n",
    "dataset_df_2 = dataset_df[dataset_df[\"rating\"]==2.0]\n",
    "dataset_df_1 = dataset_df[dataset_df[\"rating\"]==1.0]\n",
    "dataset_df_0 = dataset_df[dataset_df[\"rating\"]==0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "16183\n",
      "20931\n",
      "47619\n",
      "111070\n",
      "249099\n"
     ]
    }
   ],
   "source": [
    "print (len(dataset_df_0))\n",
    "print (len(dataset_df_1))\n",
    "print (len(dataset_df_2))\n",
    "print (len(dataset_df_3))\n",
    "print (len(dataset_df_4))\n",
    "print (len(dataset_df_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This book was a philosophical touchstone for insecure Boomers of the mid-1970s. Everybody I knew in those days had to be able to discuss it intelligently or risk being thought to have a gap in our characters as people. A folk/ talking blues singer of that era (I forget who) referred to this book in a lyric:\"...a copy of Kahlil Gibran\\'s \\'The Prophet\\' with all the significant passages highlighted--the whole damn BOOK was highlited...\"In truth, the whole phenomenon was symptomatic of the societal immaturity of my generation as young adults. It taught us all sorts of theoretical concepts of human nature that were not necessarily reflective of the real world--consideration, the dignity of each person, peace, love, repudiation of prejudice--all of this in a world that anything but reflected such beliefs in Gibran\\'s day. And except for the hippy-dippy pseudo-enlightenment we tried to cram down the world\\'s throat in our day, our peculiar era was no better. We just used Gibran and other such philosophers to peer-pressure one another into self-defeating meekness. If someone you knew was erudite enough to understand philosophy but didn\\'t have the moxie to stand up to people when he should, Gibran was the ideal way to make him a bona fide doormat and make him think he liked it. I won\\'t even try to speculate how \"relevant\" Gibran is nowadays. From the perspective of a sadder but wiser man--or at least not quite as stupid--I give you this Sting lyric from the song \"Consider Me Gone\" for consideration:\"To search for perfectionIs all very wellBut to wait for HeavenIs to live here in Hell\"'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df_1.iloc[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset_df_1_train = dataset_df_1.iloc[0:5000]\n",
    "dataset_df_1_test = dataset_df_1.iloc[5000:6000]\n",
    "dataset_df_2_train = dataset_df_2.iloc[0:5000]\n",
    "dataset_df_2_test = dataset_df_2.iloc[5000:6000]\n",
    "dataset_df_3_train = dataset_df_3.iloc[0:5000]\n",
    "dataset_df_3_test = dataset_df_3.iloc[5000:6000]\n",
    "dataset_df_4_train = dataset_df_4.iloc[0:5000]\n",
    "dataset_df_4_test = dataset_df_4.iloc[5000:6000]\n",
    "dataset_df_5_train = dataset_df_5.iloc[0:5000]\n",
    "dataset_df_5_test = dataset_df_5.iloc[5000:6000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>This book was a philosophical touchstone for i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I really wish publishers would rate books like...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.0</td>\n",
       "      <td>like many others, i was disappointed by the di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I've decided I just can't finish this book. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Some parts are entertaining enough, but left m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rating                                        review_text\n",
       "7      1.0  This book was a philosophical touchstone for i...\n",
       "28     1.0  I really wish publishers would rate books like...\n",
       "50     1.0  like many others, i was disappointed by the di...\n",
       "89     1.0  I've decided I just can't finish this book. Th...\n",
       "99     1.0  Some parts are entertaining enough, but left m..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df_1_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames_train = [dataset_df_5_train, dataset_df_4_train, dataset_df_3_train,dataset_df_2_train,dataset_df_1_train]\n",
    "frames_test = [dataset_df_5_test, dataset_df_4_test, dataset_df_3_test,dataset_df_2_test,dataset_df_1_test]\n",
    "\n",
    "dataset_df_train = pd.concat(frames_train)\n",
    "dataset_df_test = pd.concat(frames_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset_df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Clean the reviews\n",
    "def data_cleaning (raw_review_str):\n",
    "    ## remove potential HTML tag\n",
    "    review_text = BeautifulSoup(raw_review_str).get_text()\n",
    "    ## remove non-letter \n",
    "    review_letter = re.sub(\"[^a-zA-Z]\",\" \",review_text)\n",
    "    ## convert to lower case and split the list\n",
    "    review_lower_list = review_letter.lower().split()\n",
    "    ## remove stop words and stemming\n",
    "    stops_eng = set(stopwords.words(\"english\"))\n",
    "    stemmer = nltk.wordnet.WordNetLemmatizer()\n",
    "    #review_nostopwords_stemmed = [stemmer.lemmatize(w) for w in review_lower_list]\n",
    "    review_nostopwords_stemmed = [stemmer.lemmatize(w) for w in review_lower_list if w not in stops_eng]\n",
    "    ## return \n",
    "    return \" \".join(review_lower_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xinmu/anaconda/envs/py36/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/xinmu/anaconda/envs/py36/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"html.parser\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "dataset_df_train[\"review_cleaned\"] = dataset_df_train[\"review_text\"].apply(data_cleaning)\n",
    "dataset_df_test[\"review_cleaned\"] = dataset_df_test[\"review_text\"].apply(data_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Put all the review of train_set in a list to generate the features\n",
    "clean_train_reviews = []\n",
    "for i in dataset_df_train[\"review_cleaned\"]:\n",
    "    clean_train_reviews.append(i)\n",
    "\n",
    "clean_test_reviews = []\n",
    "for i in dataset_df_test[\"review_cleaned\"]:\n",
    "    clean_test_reviews.append(i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Generate Features (bag of words)\n",
    "vectorizer = TfidfVectorizer(analyzer = \"word\", ngram_range=(1, 2), tokenizer = None, preprocessor = None, stop_words = None,max_features=2000)\n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "test_data_features = vectorizer.transform(clean_test_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_features = train_data_features.toarray()\n",
    "test_data_features = test_data_features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovo', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "clf.fit(train_data_features, dataset_df_train[\"rating\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction_svm = clf.predict(test_data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(prediction_svm))\n",
    "print(type(dataset_df_test['rating']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_svm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df_test['rating'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction accuracy is 0.387800\n"
     ]
    }
   ],
   "source": [
    "print(\"prediction accuracy is %f\" % ((dataset_df_test['rating'] == prediction_svm).sum()/len(dataset_df_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
